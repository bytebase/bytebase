package oracle

import (
	"context"
	"database/sql"
	"fmt"
	"slices"
	"strconv"
	"strings"
	"testing"
	"time"

	"github.com/docker/docker/api/types/container"
	"github.com/google/go-cmp/cmp"
	"github.com/pkg/errors"
	"github.com/stretchr/testify/require"
	"github.com/testcontainers/testcontainers-go"
	"github.com/testcontainers/testcontainers-go/wait"
	"google.golang.org/protobuf/testing/protocmp"

	"github.com/bytebase/bytebase/backend/plugin/db"
	oracledb "github.com/bytebase/bytebase/backend/plugin/db/oracle"
	plsqlparser "github.com/bytebase/bytebase/backend/plugin/parser/plsql"
	"github.com/bytebase/bytebase/backend/plugin/schema"
	"github.com/bytebase/bytebase/backend/store/model"
	storepb "github.com/bytebase/bytebase/proto/generated-go/store"
)

// TestGenerateMigrationWithTestcontainer tests the generate migration function
// by applying migrations and rollback to verify the schema can be restored.
func TestGenerateMigrationWithTestcontainer(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping Oracle testcontainer test in short mode")
	}

	ctx := context.Background()

	// Use Oracle Free image (Oracle 23c Free) slim version
	imageName := "gvenzl/oracle-free:slim"

	// Start Oracle container
	req := testcontainers.ContainerRequest{
		Image: imageName,
		Env: map[string]string{
			"ORACLE_PASSWORD":   "test123",
			"APP_USER":          "testuser",
			"APP_USER_PASSWORD": "testpass",
		},
		ExposedPorts: []string{"1521/tcp"},
		WaitingFor: wait.ForLog("DATABASE IS READY TO USE!").
			WithStartupTimeout(10 * time.Minute),
		HostConfigModifier: func(hc *container.HostConfig) {
			hc.ShmSize = 1 * 1024 * 1024 * 1024 // 1GB shared memory
		},
	}

	container, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{
		ContainerRequest: req,
		Started:          true,
	})
	if err != nil {
		// Get detailed logs for debugging
		if container != nil {
			logs, logErr := container.Logs(ctx)
			if logErr == nil {
				buf := make([]byte, 10000)
				n, _ := logs.Read(buf)
				t.Logf("Container logs on failure: %s", string(buf[:n]))
			}
		}
		require.NoError(t, err, "Failed to start Oracle container")
	}
	defer func() {
		if err := container.Terminate(ctx); err != nil {
			t.Logf("failed to terminate container: %s", err)
		}
	}()

	// Get connection details
	host, err := container.Host(ctx)
	require.NoError(t, err)
	port, err := container.MappedPort(ctx, "1521")
	require.NoError(t, err)

	// Test cases with various schema changes
	testCases := []struct {
		name          string
		initialSchema string
		migrationDDL  string
		description   string
	}{
		{
			name: "basic_table_operations",
			initialSchema: `
CREATE TABLE USERS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    USERNAME VARCHAR2(50) NOT NULL,
    EMAIL VARCHAR2(100) NOT NULL,
    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE POSTS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    USER_ID NUMBER NOT NULL,
    TITLE VARCHAR2(200) NOT NULL,
    CONTENT CLOB,
    CONSTRAINT FK_USER FOREIGN KEY (USER_ID) REFERENCES USERS(ID)
);

CREATE INDEX IDX_POSTS_USER_ID ON POSTS(USER_ID);
`,
			migrationDDL: `
-- Add new column
ALTER TABLE USERS ADD IS_ACTIVE NUMBER(1) DEFAULT 1;

-- Create new table
CREATE TABLE COMMENTS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    POST_ID NUMBER NOT NULL,
    USER_ID NUMBER NOT NULL,
    CONTENT CLOB NOT NULL,
    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT FK_POST FOREIGN KEY (POST_ID) REFERENCES POSTS(ID),
    CONSTRAINT FK_COMMENT_USER FOREIGN KEY (USER_ID) REFERENCES USERS(ID)
);

-- Add new index
CREATE INDEX IDX_USERS_EMAIL ON USERS(EMAIL);

-- Add check constraint
ALTER TABLE POSTS ADD CONSTRAINT CHECK_TITLE_LENGTH CHECK (LENGTH(TITLE) > 0);
`,
			description: "Basic table operations with columns, constraints, and indexes",
		},
		{
			name: "views_and_functions",
			initialSchema: `
CREATE TABLE PRODUCTS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    NAME VARCHAR2(100) NOT NULL,
    PRICE NUMBER(10, 2) NOT NULL,
    STOCK NUMBER DEFAULT 0
);

CREATE TABLE ORDERS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    PRODUCT_ID NUMBER NOT NULL,
    QUANTITY NUMBER NOT NULL,
    TOTAL NUMBER(10, 2),
    CONSTRAINT FK_PRODUCT FOREIGN KEY (PRODUCT_ID) REFERENCES PRODUCTS(ID)
);
`,
			migrationDDL: `
-- Create view
CREATE VIEW PRODUCT_INVENTORY AS
SELECT 
    P.ID,
    P.NAME,
    P.PRICE,
    P.STOCK,
    NVL(SUM(O.QUANTITY), 0) AS TOTAL_ORDERED
FROM PRODUCTS P
LEFT JOIN ORDERS O ON P.ID = O.PRODUCT_ID
GROUP BY P.ID, P.NAME, P.PRICE, P.STOCK;

-- Create function
CREATE OR REPLACE FUNCTION CALCULATE_ORDER_TOTAL(P_PRODUCT_ID NUMBER, P_QUANTITY NUMBER)
RETURN NUMBER
IS
    V_PRICE NUMBER(10, 2);
BEGIN
    SELECT PRICE INTO V_PRICE FROM PRODUCTS WHERE ID = P_PRODUCT_ID;
    RETURN P_QUANTITY * V_PRICE;
EXCEPTION
    WHEN NO_DATA_FOUND THEN
        RETURN 0;
END;
/

-- Create materialized view
CREATE MATERIALIZED VIEW PRODUCT_STATS AS
SELECT 
    PRODUCT_ID,
    COUNT(*) AS ORDER_COUNT,
    SUM(QUANTITY) AS TOTAL_QUANTITY,
    SUM(TOTAL) AS TOTAL_REVENUE
FROM ORDERS
GROUP BY PRODUCT_ID;

-- Create index on materialized view
CREATE INDEX IDX_PRODUCT_STATS_REVENUE ON PRODUCT_STATS(TOTAL_REVENUE DESC);
`,
			description: "Views, functions, and materialized views",
		},
		{
			name: "sequences",
			initialSchema: `
CREATE TABLE ITEMS (
    ID NUMBER PRIMARY KEY,
    NAME VARCHAR2(100) NOT NULL
);
`,
			migrationDDL: `
-- Create sequence
CREATE SEQUENCE ORDER_SEQ START WITH 1000 INCREMENT BY 10;

-- Create table using sequence
CREATE TABLE SALES_ORDERS (
    ID NUMBER DEFAULT ORDER_SEQ.NEXTVAL PRIMARY KEY,
    ITEM_ID NUMBER NOT NULL,
    QUANTITY NUMBER NOT NULL,
    CONSTRAINT FK_ITEM FOREIGN KEY (ITEM_ID) REFERENCES ITEMS(ID)
);
`,
			description: "Sequences and their usage in tables",
		},
		{
			name: "drop_indexes_and_constraints",
			initialSchema: `
CREATE TABLE PRODUCTS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    NAME VARCHAR2(100) NOT NULL,
    CATEGORY VARCHAR2(50),
    PRICE NUMBER(10, 2),
    SUPPLIER_ID NUMBER
);

CREATE INDEX IDX_PRODUCTS_CATEGORY ON PRODUCTS(CATEGORY);
CREATE INDEX IDX_PRODUCTS_PRICE ON PRODUCTS(PRICE);
CREATE UNIQUE INDEX IDX_PRODUCTS_NAME ON PRODUCTS(NAME);

ALTER TABLE PRODUCTS ADD CONSTRAINT CHECK_PRICE_POSITIVE CHECK (PRICE > 0);
ALTER TABLE PRODUCTS ADD CONSTRAINT CHECK_NAME_LENGTH CHECK (LENGTH(NAME) >= 3);
`,
			migrationDDL: `
-- Drop indexes and constraints
DROP INDEX IDX_PRODUCTS_CATEGORY;
DROP INDEX IDX_PRODUCTS_PRICE;
DROP INDEX IDX_PRODUCTS_NAME;
ALTER TABLE PRODUCTS DROP CONSTRAINT CHECK_PRICE_POSITIVE;
ALTER TABLE PRODUCTS DROP CONSTRAINT CHECK_NAME_LENGTH;
`,
			description: "Drop indexes and constraints from tables",
		},
		{
			name: "drop_views_and_functions",
			initialSchema: `
CREATE TABLE SALES (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    PRODUCT_NAME VARCHAR2(100) NOT NULL,
    SALE_AMOUNT NUMBER(10, 2) NOT NULL,
    SALE_DATE DATE NOT NULL
);

CREATE VIEW MONTHLY_SALES AS
SELECT 
    EXTRACT(YEAR FROM SALE_DATE) AS YEAR_VAL,
    EXTRACT(MONTH FROM SALE_DATE) AS MONTH_VAL,
    SUM(SALE_AMOUNT) AS TOTAL_SALES
FROM SALES
GROUP BY EXTRACT(YEAR FROM SALE_DATE), EXTRACT(MONTH FROM SALE_DATE);

CREATE MATERIALIZED VIEW TOP_PRODUCTS AS
SELECT 
    PRODUCT_NAME,
    COUNT(*) AS SALE_COUNT,
    SUM(SALE_AMOUNT) AS TOTAL_REVENUE
FROM SALES
GROUP BY PRODUCT_NAME
ORDER BY SUM(SALE_AMOUNT) DESC;

CREATE OR REPLACE FUNCTION GET_MONTHLY_TOTAL(YEAR_PARAM NUMBER, MONTH_PARAM NUMBER)
RETURN NUMBER
IS
    V_TOTAL NUMBER;
BEGIN
    SELECT NVL(SUM(SALE_AMOUNT), 0) INTO V_TOTAL
    FROM SALES
    WHERE EXTRACT(YEAR FROM SALE_DATE) = YEAR_PARAM
    AND EXTRACT(MONTH FROM SALE_DATE) = MONTH_PARAM;
    
    RETURN V_TOTAL;
END;
/

CREATE OR REPLACE FUNCTION CALCULATE_DISCOUNT(AMOUNT NUMBER)
RETURN NUMBER
IS
BEGIN
    RETURN AMOUNT * 0.1;
END;
/
`,
			migrationDDL: `
-- Drop views and functions
DROP MATERIALIZED VIEW TOP_PRODUCTS;
DROP VIEW MONTHLY_SALES;
DROP FUNCTION GET_MONTHLY_TOTAL;
DROP FUNCTION CALCULATE_DISCOUNT;
`,
			description: "Drop views and functions that depend on tables",
		},
		{
			name: "alter_table_columns",
			initialSchema: `
CREATE TABLE PRODUCTS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    NAME VARCHAR2(50) NOT NULL,
    PRICE NUMBER(8, 2) NOT NULL,
    DESCRIPTION CLOB,
    CATEGORY VARCHAR2(30),
    IS_ACTIVE NUMBER(1) DEFAULT 1
);

CREATE INDEX IDX_PRODUCTS_CATEGORY ON PRODUCTS(CATEGORY);
CREATE INDEX IDX_PRODUCTS_PRICE ON PRODUCTS(PRICE);
`,
			migrationDDL: `
-- Alter table operations
ALTER TABLE PRODUCTS ADD CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP;
ALTER TABLE PRODUCTS ADD STOCK_QUANTITY NUMBER DEFAULT 0;
ALTER TABLE PRODUCTS ADD WEIGHT NUMBER(5, 2);

-- Change column types and constraints
ALTER TABLE PRODUCTS MODIFY NAME VARCHAR2(100);
ALTER TABLE PRODUCTS MODIFY PRICE NUMBER(10, 2);
ALTER TABLE PRODUCTS MODIFY DESCRIPTION NOT NULL;

-- Add constraints
ALTER TABLE PRODUCTS ADD CONSTRAINT CHECK_PRICE_POSITIVE CHECK (PRICE > 0);
ALTER TABLE PRODUCTS ADD CONSTRAINT CHECK_STOCK_NON_NEGATIVE CHECK (STOCK_QUANTITY >= 0);

-- Add new index
CREATE INDEX IDX_PRODUCTS_CREATED_AT ON PRODUCTS(CREATED_AT);
CREATE UNIQUE INDEX IDX_PRODUCTS_NAME_CATEGORY ON PRODUCTS(NAME, CATEGORY);
`,
			description: "Alter table with column additions, type changes, and constraints",
		},
		{
			name: "drop_and_recreate_constraints",
			initialSchema: `
CREATE TABLE AUTHORS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    NAME VARCHAR2(100) NOT NULL,
    EMAIL VARCHAR2(100) UNIQUE
);

CREATE TABLE BOOKS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    TITLE VARCHAR2(200) NOT NULL,
    AUTHOR_ID NUMBER NOT NULL,
    ISBN VARCHAR2(20) UNIQUE,
    PUBLISHED_YEAR NUMBER,
    PRICE NUMBER(8, 2),
    CONSTRAINT FK_AUTHOR FOREIGN KEY (AUTHOR_ID) REFERENCES AUTHORS(ID),
    CONSTRAINT CHECK_YEAR_VALID CHECK (PUBLISHED_YEAR >= 1000 AND PUBLISHED_YEAR <= 2100),
    CONSTRAINT CHECK_PRICE_POSITIVE CHECK (PRICE > 0)
);

CREATE INDEX IDX_BOOKS_AUTHOR ON BOOKS(AUTHOR_ID);
CREATE INDEX IDX_BOOKS_YEAR ON BOOKS(PUBLISHED_YEAR);
`,
			migrationDDL: `
-- Drop and recreate foreign key with different options
ALTER TABLE BOOKS DROP CONSTRAINT FK_AUTHOR;
ALTER TABLE BOOKS ADD CONSTRAINT FK_AUTHOR_NEW FOREIGN KEY (AUTHOR_ID) REFERENCES AUTHORS(ID) ON DELETE CASCADE;

-- Drop and modify check constraints
ALTER TABLE BOOKS DROP CONSTRAINT CHECK_YEAR_VALID;
ALTER TABLE BOOKS ADD CONSTRAINT CHECK_YEAR_EXTENDED CHECK (PUBLISHED_YEAR >= 1000 AND PUBLISHED_YEAR <= 2030);

-- Add new constraints
ALTER TABLE BOOKS ADD CONSTRAINT CHECK_TITLE_LENGTH CHECK (LENGTH(TITLE) >= 3);
`,
			description: "Drop and recreate constraints with different definitions",
		},
		{
			name: "drop_sequence",
			initialSchema: `
CREATE SEQUENCE TRANSACTION_SEQ START WITH 1000;

CREATE TABLE SIMPLE_LOG (
    ID NUMBER DEFAULT TRANSACTION_SEQ.NEXTVAL PRIMARY KEY,
    MESSAGE CLOB NOT NULL
);
`,
			migrationDDL: `
-- Drop table and sequence
DROP TABLE SIMPLE_LOG;
DROP SEQUENCE TRANSACTION_SEQ;
`,
			description: "Drop sequence and dependent table",
		},
		{
			name: "complex_view_dependencies",
			initialSchema: `
CREATE TABLE DEPARTMENTS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    NAME VARCHAR2(100) NOT NULL,
    MANAGER_ID NUMBER
);

CREATE TABLE EMPLOYEES (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    NAME VARCHAR2(100) NOT NULL,
    DEPARTMENT_ID NUMBER,
    SALARY NUMBER(10, 2),
    CONSTRAINT FK_DEPT FOREIGN KEY (DEPARTMENT_ID) REFERENCES DEPARTMENTS(ID)
);

-- Self-referencing foreign key
ALTER TABLE DEPARTMENTS ADD CONSTRAINT FK_MANAGER FOREIGN KEY (MANAGER_ID) REFERENCES EMPLOYEES(ID);
`,
			migrationDDL: `
-- Create base view
CREATE VIEW DEPT_EMPLOYEE_COUNT AS
SELECT D.ID AS DEPT_ID, D.NAME AS DEPT_NAME, COUNT(E.ID) AS EMP_COUNT
FROM DEPARTMENTS D
LEFT JOIN EMPLOYEES E ON D.ID = E.DEPARTMENT_ID
GROUP BY D.ID, D.NAME;

-- Create dependent view
CREATE VIEW DEPT_SUMMARY AS
SELECT 
    DEC.DEPT_ID,
    DEC.DEPT_NAME,
    DEC.EMP_COUNT,
    NVL(AVG(E.SALARY), 0) AS AVG_SALARY
FROM DEPT_EMPLOYEE_COUNT DEC
LEFT JOIN EMPLOYEES E ON DEC.DEPT_ID = E.DEPARTMENT_ID
GROUP BY DEC.DEPT_ID, DEC.DEPT_NAME, DEC.EMP_COUNT;

-- Create highly dependent view
CREATE VIEW DEPT_MANAGER_SUMMARY AS
SELECT 
    DS.DEPT_ID,
    DS.DEPT_NAME,
    DS.EMP_COUNT,
    DS.AVG_SALARY,
    M.NAME AS MANAGER_NAME
FROM DEPT_SUMMARY DS
JOIN DEPARTMENTS D ON DS.DEPT_ID = D.ID
LEFT JOIN EMPLOYEES M ON D.MANAGER_ID = M.ID;

-- Create materialized view with complex dependencies
CREATE MATERIALIZED VIEW MV_DEPT_STATS AS
SELECT 
    D.ID AS DEPT_ID,
    D.NAME AS DEPT_NAME,
    COUNT(E.ID) AS TOTAL_EMPLOYEES,
    NVL(SUM(E.SALARY), 0) AS TOTAL_PAYROLL,
    NVL(AVG(E.SALARY), 0) AS AVG_SALARY,
    NVL(MAX(E.SALARY), 0) AS MAX_SALARY,
    NVL(MIN(E.SALARY), 0) AS MIN_SALARY
FROM DEPARTMENTS D
LEFT JOIN EMPLOYEES E ON D.ID = E.DEPARTMENT_ID
GROUP BY D.ID, D.NAME;

-- Create index on materialized view
CREATE INDEX IDX_MV_DEPT_PAYROLL ON MV_DEPT_STATS(TOTAL_PAYROLL DESC);
`,
			description: "Complex view dependencies with multiple levels and materialized views",
		},
		{
			name: "circular_foreign_key_dependencies",
			initialSchema: `
CREATE TABLE CUSTOMERS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    NAME VARCHAR2(100) NOT NULL,
    PREFERRED_ORDER_ID NUMBER
);

CREATE TABLE ORDERS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    CUSTOMER_ID NUMBER NOT NULL,
    ORDER_DATE DATE DEFAULT SYSDATE,
    TOTAL_AMOUNT NUMBER(10, 2)
);
`,
			migrationDDL: `
-- Create circular foreign key dependencies
ALTER TABLE CUSTOMERS ADD CONSTRAINT FK_PREFERRED_ORDER FOREIGN KEY (PREFERRED_ORDER_ID) REFERENCES ORDERS(ID);
ALTER TABLE ORDERS ADD CONSTRAINT FK_CUSTOMER FOREIGN KEY (CUSTOMER_ID) REFERENCES CUSTOMERS(ID);

-- Add more tables with complex relationships
CREATE TABLE ORDER_ITEMS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    ORDER_ID NUMBER NOT NULL,
    PRODUCT_NAME VARCHAR2(100) NOT NULL,
    QUANTITY NUMBER NOT NULL,
    UNIT_PRICE NUMBER(10, 2) NOT NULL,
    CONSTRAINT FK_ORDER_ITEM FOREIGN KEY (ORDER_ID) REFERENCES ORDERS(ID) ON DELETE CASCADE
);

-- Create trigger to update order total
CREATE OR REPLACE TRIGGER TRG_UPDATE_ORDER_TOTAL
AFTER INSERT OR UPDATE OR DELETE ON ORDER_ITEMS
FOR EACH ROW
DECLARE
    V_ORDER_ID NUMBER;
    V_TOTAL NUMBER(10, 2);
BEGIN
    -- Get order ID
    IF INSERTING OR UPDATING THEN
        V_ORDER_ID := :NEW.ORDER_ID;
    ELSE
        V_ORDER_ID := :OLD.ORDER_ID;
    END IF;
    
    -- Calculate new total
    SELECT NVL(SUM(QUANTITY * UNIT_PRICE), 0) INTO V_TOTAL
    FROM ORDER_ITEMS
    WHERE ORDER_ID = V_ORDER_ID;
    
    -- Update order total
    UPDATE ORDERS SET TOTAL_AMOUNT = V_TOTAL WHERE ID = V_ORDER_ID;
END;
/
`,
			description: "Circular foreign key dependencies and triggers",
		},
		{
			name: "advanced_indexes_and_constraints",
			initialSchema: `
CREATE TABLE SALES_DATA (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY,
    SALE_DATE DATE NOT NULL,
    CUSTOMER_ID NUMBER NOT NULL,
    PRODUCT_ID NUMBER NOT NULL,
    AMOUNT NUMBER(10, 2) NOT NULL,
    REGION VARCHAR2(50) NOT NULL
);
`,
			migrationDDL: `
-- Create function-based index
CREATE INDEX IDX_SALES_MONTH_YEAR ON SALES_DATA(EXTRACT(YEAR FROM SALE_DATE), EXTRACT(MONTH FROM SALE_DATE));

-- Create composite index with mixed sort order
CREATE INDEX IDX_SALES_REGION_AMOUNT ON SALES_DATA(REGION ASC, AMOUNT DESC);

-- Create unique constraint on composite columns
ALTER TABLE SALES_DATA ADD CONSTRAINT UK_SALES_DATE_CUSTOMER UNIQUE (SALE_DATE, CUSTOMER_ID, PRODUCT_ID);

-- Create check constraint with complex expression
ALTER TABLE SALES_DATA ADD CONSTRAINT CHK_AMOUNT_RANGE CHECK (AMOUNT > 0 AND AMOUNT <= 999999.99);

-- Create conditional check constraint
ALTER TABLE SALES_DATA ADD CONSTRAINT CHK_REGION_VALID CHECK (REGION IN ('NORTH', 'SOUTH', 'EAST', 'WEST', 'CENTRAL'));
`,
			description: "Advanced Oracle-specific indexes and complex constraints",
		},
		{
			name: "stored_procedures_and_functions",
			initialSchema: `
CREATE TABLE AUDIT_LOG (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    TABLE_NAME VARCHAR2(100) NOT NULL,
    OPERATION VARCHAR2(10) NOT NULL,
    OLD_VALUES CLOB,
    NEW_VALUES CLOB,
    TIMESTAMP TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    USER_NAME VARCHAR2(100) DEFAULT USER
);
`,
			migrationDDL: `
-- Create stored procedure
CREATE OR REPLACE PROCEDURE LOG_AUDIT(
    P_TABLE_NAME VARCHAR2,
    P_OPERATION VARCHAR2,
    P_OLD_VALUES CLOB DEFAULT NULL,
    P_NEW_VALUES CLOB DEFAULT NULL
)
IS
BEGIN
    INSERT INTO AUDIT_LOG (TABLE_NAME, OPERATION, OLD_VALUES, NEW_VALUES)
    VALUES (P_TABLE_NAME, P_OPERATION, P_OLD_VALUES, P_NEW_VALUES);
    COMMIT;
EXCEPTION
    WHEN OTHERS THEN
        ROLLBACK;
        RAISE;
END;
/

-- Create function with complex logic
CREATE OR REPLACE FUNCTION CALCULATE_BUSINESS_DAYS(
    P_START_DATE DATE,
    P_END_DATE DATE
) RETURN NUMBER
IS
    V_DAYS NUMBER := 0;
    V_CURRENT_DATE DATE := P_START_DATE;
BEGIN
    WHILE V_CURRENT_DATE <= P_END_DATE LOOP
        -- Skip weekends (Saturday = 7, Sunday = 1)
        IF TO_CHAR(V_CURRENT_DATE, 'D') NOT IN ('1', '7') THEN
            V_DAYS := V_DAYS + 1;
        END IF;
        V_CURRENT_DATE := V_CURRENT_DATE + 1;
    END LOOP;
    
    RETURN V_DAYS;
END;
/

-- Create another function for testing dependencies
CREATE OR REPLACE FUNCTION GET_AUDIT_COUNT(P_TABLE_NAME VARCHAR2) RETURN NUMBER
IS
    V_COUNT NUMBER;
BEGIN
    SELECT COUNT(*) INTO V_COUNT
    FROM AUDIT_LOG
    WHERE TABLE_NAME = P_TABLE_NAME;
    
    RETURN V_COUNT;
END;
/
`,
			description: "Stored procedures and functions with dependencies",
		},
		{
			name: "synonyms_and_complex_references",
			initialSchema: `
CREATE TABLE LOCAL_PRODUCTS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    NAME VARCHAR2(100) NOT NULL,
    PRICE NUMBER(10, 2),
    CATEGORY VARCHAR2(50)
);

CREATE TABLE LOCAL_CUSTOMERS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    NAME VARCHAR2(100) NOT NULL,
    EMAIL VARCHAR2(100),
    PHONE VARCHAR2(20)
);
`,
			migrationDDL: `
-- Create synonyms for easier access
CREATE OR REPLACE SYNONYM PRODUCTS FOR LOCAL_PRODUCTS;
CREATE OR REPLACE SYNONYM CUSTOMERS FOR LOCAL_CUSTOMERS;

-- Create view using synonyms
CREATE VIEW PRODUCT_CUSTOMER_SUMMARY AS
SELECT 
    'PRODUCT' AS ENTITY_TYPE,
    TO_CHAR(ID) AS ENTITY_ID,
    NAME AS ENTITY_NAME,
    NULL AS EMAIL
FROM PRODUCTS
UNION ALL
SELECT 
    'CUSTOMER' AS ENTITY_TYPE,
    TO_CHAR(ID) AS ENTITY_ID,
    NAME AS ENTITY_NAME,
    EMAIL
FROM CUSTOMERS;

-- Create sequence with specific naming pattern
CREATE SEQUENCE SEQ_TRANSACTION_ID START WITH 10000 INCREMENT BY 1;

-- Create table using sequence and synonyms
CREATE TABLE TRANSACTIONS (
    ID NUMBER DEFAULT SEQ_TRANSACTION_ID.NEXTVAL PRIMARY KEY,
    CUSTOMER_ID NUMBER NOT NULL,
    PRODUCT_ID NUMBER NOT NULL,
    TRANSACTION_DATE DATE DEFAULT SYSDATE,
    AMOUNT NUMBER(10, 2),
    CONSTRAINT FK_TRANS_CUSTOMER FOREIGN KEY (CUSTOMER_ID) REFERENCES CUSTOMERS(ID),
    CONSTRAINT FK_TRANS_PRODUCT FOREIGN KEY (PRODUCT_ID) REFERENCES PRODUCTS(ID)
);
`,
			description: "Synonyms, sequences with specific patterns, and complex references",
		},
		{
			name: "edge_case_column_operations",
			initialSchema: `
CREATE TABLE TEST_COLUMNS (
    ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    COL_VARCHAR VARCHAR2(50),
    COL_NUMBER NUMBER(10,2),
    COL_DATE DATE,
    COL_CLOB CLOB,
    COL_NULLABLE VARCHAR2(100),
    COL_WITH_DEFAULT VARCHAR2(50) DEFAULT 'DEFAULT_VALUE'
);
`,
			migrationDDL: `
-- Test various column modifications
ALTER TABLE TEST_COLUMNS MODIFY COL_VARCHAR VARCHAR2(200);
ALTER TABLE TEST_COLUMNS MODIFY COL_NUMBER NUMBER(15,3);
ALTER TABLE TEST_COLUMNS MODIFY COL_NULLABLE NOT NULL;
ALTER TABLE TEST_COLUMNS MODIFY COL_WITH_DEFAULT DEFAULT 'NEW_DEFAULT';

-- Add columns with various data types and constraints
ALTER TABLE TEST_COLUMNS ADD COL_TIMESTAMP TIMESTAMP DEFAULT CURRENT_TIMESTAMP;
ALTER TABLE TEST_COLUMNS ADD COL_BOOLEAN NUMBER(1) CHECK (COL_BOOLEAN IN (0,1));

-- Drop some columns
ALTER TABLE TEST_COLUMNS DROP COLUMN COL_CLOB;

-- Add constraints
ALTER TABLE TEST_COLUMNS ADD CONSTRAINT CHK_VARCHAR_LENGTH CHECK (LENGTH(COL_VARCHAR) >= 5);
ALTER TABLE TEST_COLUMNS ADD CONSTRAINT CHK_NUMBER_POSITIVE CHECK (COL_NUMBER > 0);
`,
			description: "Edge cases for column operations and data type modifications",
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			// Step 1: Initialize the database schema and get schema result A
			portInt, err := strconv.Atoi(port.Port())
			require.NoError(t, err)
			testDB, err := openTestDatabase(host, portInt, "testuser", "testpass")
			require.NoError(t, err)
			defer testDB.Close()

			// Set current schema to TESTUSER
			_, err = testDB.Exec("ALTER SESSION SET CURRENT_SCHEMA = TESTUSER")
			require.NoError(t, err)

			// Clean up any existing objects
			_, _ = testDB.Exec("BEGIN FOR c IN (SELECT table_name FROM user_tables) LOOP EXECUTE IMMEDIATE 'DROP TABLE ' || c.table_name || ' CASCADE CONSTRAINTS'; END LOOP; END;")
			_, _ = testDB.Exec("BEGIN FOR c IN (SELECT view_name FROM user_views) LOOP EXECUTE IMMEDIATE 'DROP VIEW ' || c.view_name; END LOOP; END;")
			_, _ = testDB.Exec("BEGIN FOR c IN (SELECT mview_name FROM user_mviews) LOOP EXECUTE IMMEDIATE 'DROP MATERIALIZED VIEW ' || c.mview_name; END LOOP; END;")
			_, _ = testDB.Exec("BEGIN FOR c IN (SELECT object_name FROM user_objects WHERE object_type = 'FUNCTION') LOOP EXECUTE IMMEDIATE 'DROP FUNCTION ' || c.object_name; END LOOP; END;")
			_, _ = testDB.Exec("BEGIN FOR c IN (SELECT sequence_name FROM user_sequences) LOOP EXECUTE IMMEDIATE 'DROP SEQUENCE ' || c.sequence_name; END LOOP; END;")

			// Execute initial schema
			if err := executeStatements(testDB, tc.initialSchema); err != nil {
				t.Fatalf("Failed to execute initial schema: %v", err)
			}

			schemaA, err := getSyncMetadataForGenerateMigration(ctx, host, portInt)
			require.NoError(t, err)

			// Step 2: Do some migration and get schema result B
			if err := executeStatements(testDB, tc.migrationDDL); err != nil {
				t.Fatalf("Failed to execute migration DDL: %v", err)
			}

			schemaB, err := getSyncMetadataForGenerateMigration(ctx, host, portInt)
			require.NoError(t, err)

			// Step 3: Call generate migration to get the rollback DDL
			// Convert to model.DatabaseSchema
			dbSchemaA := model.NewDatabaseSchema(schemaA, nil, nil, storepb.Engine_ORACLE, false)
			dbSchemaB := model.NewDatabaseSchema(schemaB, nil, nil, storepb.Engine_ORACLE, false)

			// Get diff from B to A (to generate rollback)
			diff, err := schema.GetDatabaseSchemaDiff(dbSchemaB, dbSchemaA)
			require.NoError(t, err)

			// Generate rollback migration
			rollbackDDL, err := schema.GenerateMigration(storepb.Engine_ORACLE, diff)
			require.NoError(t, err)

			// Step 4: Run rollback DDL and get schema result C
			if err := executeStatements(testDB, rollbackDDL); err != nil {
				t.Fatalf("Failed to execute rollback DDL: %v", err)
			}

			schemaC, err := getSyncMetadataForGenerateMigration(ctx, host, portInt)
			require.NoError(t, err)

			// Step 5: Compare schema result A and C to ensure they are the same
			normalizeMetadataForComparison(schemaA)
			normalizeMetadataForComparison(schemaC)

			// Normalize column positions to 0 before comparison to ignore position differences
			normalizeColumnPositions(schemaA)
			normalizeColumnPositions(schemaC)

			// Use cmp with protocmp for proto message comparison
			if diff := cmp.Diff(schemaA, schemaC, protocmp.Transform()); diff != "" {
				t.Errorf("Schema mismatch after rollback (-want +got):\n%s", diff)
			}
		})
	}
}

// openTestDatabase opens a connection to the test Oracle database
func openTestDatabase(host string, port int, username, password string) (*sql.DB, error) {
	dsn := fmt.Sprintf("oracle://%s:%s@%s:%d/FREEPDB1", username, password, host, port)
	db, err := sql.Open("oracle", dsn)
	if err != nil {
		return nil, err
	}
	if err := db.Ping(); err != nil {
		return nil, err
	}
	return db, nil
}

// executeStatements executes multiple SQL statements, handling both regular DDL and PL/SQL blocks
func executeStatements(db *sql.DB, statements string) error {
	// Set current schema to TESTUSER before executing any statements
	if _, err := db.Exec("ALTER SESSION SET CURRENT_SCHEMA = TESTUSER"); err != nil {
		return errors.Wrapf(err, "failed to set current schema")
	}

	// Use plsql.SplitSQL to properly split Oracle SQL statements
	stmts, err := plsqlparser.SplitSQL(statements)
	if err != nil {
		return errors.Wrapf(err, "failed to split SQL statements")
	}

	// Execute each statement
	for _, singleSQL := range stmts {
		stmt := strings.TrimSpace(singleSQL.Text)
		if stmt == "" {
			continue
		}

		// Skip pure comment lines
		if strings.HasPrefix(stmt, "--") {
			continue
		}

		// Execute the statement
		if _, err := db.Exec(stmt); err != nil {
			// Handle Oracle-specific issues where materialized views are misclassified as tables
			if strings.Contains(err.Error(), "must use DROP MATERIALIZED VIEW") {
				// Try to fix the statement by replacing DROP TABLE with DROP MATERIALIZED VIEW
				if strings.HasPrefix(strings.ToUpper(stmt), "DROP TABLE") {
					fixedStmt := strings.Replace(stmt, "DROP TABLE", "DROP MATERIALIZED VIEW", 1)
					if _, retryErr := db.Exec(fixedStmt); retryErr == nil {
						continue // Successfully executed with corrected statement
					}
				}
			}
			// Handle system-generated virtual column indexes that cannot be manually created
			if strings.Contains(err.Error(), "invalid identifier") && strings.Contains(stmt, "SYS_NC") {
				// Skip statements that reference system-generated virtual columns
				continue
			}
			return errors.Wrapf(err, "failed to execute statement: %s", stmt)
		}
	}

	return nil
}

// getSyncMetadataForGenerateMigration retrieves metadata from the live database using Driver.SyncDBSchema
func getSyncMetadataForGenerateMigration(ctx context.Context, host string, port int) (*storepb.DatabaseSchemaMetadata, error) {
	// Create a driver instance using the oracle package
	driver := &oracledb.Driver{}

	// Create connection config
	config := db.ConnectionConfig{
		DataSource: &storepb.DataSource{
			Type:        storepb.DataSourceType_ADMIN,
			Username:    "testuser",
			Host:        host,
			Port:        fmt.Sprintf("%d", port),
			Database:    "",
			ServiceName: "FREEPDB1",
		},
		Password: "testpass",
		ConnectionContext: db.ConnectionContext{
			EngineVersion: "23.0",     // Oracle 23c Free
			DatabaseName:  "TESTUSER", // Oracle schema names are uppercase
		},
	}

	// Open connection using the driver
	openedDriver, err := driver.Open(ctx, storepb.Engine_ORACLE, config)
	if err != nil {
		return nil, err
	}
	defer openedDriver.Close(ctx)

	// Use SyncDBSchema to get the metadata
	oracleDriver, ok := openedDriver.(*oracledb.Driver)
	if !ok {
		return nil, errors.New("failed to cast to oracle.Driver")
	}

	metadata, err := oracleDriver.SyncDBSchema(ctx)
	if err != nil {
		return nil, err
	}

	return metadata, nil
}

// normalizeMetadataForComparison normalizes metadata to ignore differences that don't affect schema equality
func normalizeMetadataForComparison(metadata *storepb.DatabaseSchemaMetadata) {
	// Clear database name as it might differ
	metadata.Name = ""

	// Normalize schemas
	for _, schema := range metadata.Schemas {
		// Normalize tables
		for _, table := range schema.Tables {
			table.DataSize = 0
			table.IndexSize = 0
			table.RowCount = 0

			// Filter out system-generated indexes that reference virtual columns
			var filteredIndexes []*storepb.IndexMetadata
			for _, idx := range table.Indexes {
				// Skip indexes that reference system-generated virtual columns
				hasVirtualColumn := false
				for _, expr := range idx.Expressions {
					if strings.HasPrefix(expr, "SYS_NC") {
						hasVirtualColumn = true
						break
					}
				}
				if !hasVirtualColumn {
					filteredIndexes = append(filteredIndexes, idx)
				}
			}
			table.Indexes = filteredIndexes

			// Sort columns by name for consistent comparison
			sortColumnsByName(table.Columns)

			// Sort indexes by name
			sortIndexesByName(table.Indexes)

			// Sort foreign keys by name
			sortForeignKeysByName(table.ForeignKeys)

			// Sort check constraints by name
			sortCheckConstraintsByName(table.CheckConstraints)
		}

		// Filter out system-generated sequences
		var filteredSequences []*storepb.SequenceMetadata
		for _, seq := range schema.Sequences {
			if !strings.HasPrefix(seq.Name, "ISEQ$$_") {
				filteredSequences = append(filteredSequences, seq)
			}
		}
		schema.Sequences = filteredSequences

		// Sort all collections for consistent comparison
		sortTablesByName(schema.Tables)
		sortViewsByName(schema.Views)
		sortMaterializedViewsByName(schema.MaterializedViews)
		sortFunctionsByName(schema.Functions)
		sortSequencesByName(schema.Sequences)
	}

	// Sort schemas by name
	sortSchemasByName(metadata.Schemas)

	// Sort extensions by name
	sortExtensionsByName(metadata.Extensions)
}

// Sorting helper functions
func sortSchemasByName(schemas []*storepb.SchemaMetadata) {
	slices.SortFunc(schemas, func(a, b *storepb.SchemaMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}

func sortTablesByName(tables []*storepb.TableMetadata) {
	slices.SortFunc(tables, func(a, b *storepb.TableMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}

func sortColumnsByName(columns []*storepb.ColumnMetadata) {
	slices.SortFunc(columns, func(a, b *storepb.ColumnMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}

func sortIndexesByName(indexes []*storepb.IndexMetadata) {
	slices.SortFunc(indexes, func(a, b *storepb.IndexMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}

func sortForeignKeysByName(fks []*storepb.ForeignKeyMetadata) {
	slices.SortFunc(fks, func(a, b *storepb.ForeignKeyMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}

func sortCheckConstraintsByName(checks []*storepb.CheckConstraintMetadata) {
	slices.SortFunc(checks, func(a, b *storepb.CheckConstraintMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}

// normalizeColumnPositions sets all column positions to 0 to ignore position differences during comparison
func normalizeColumnPositions(metadata *storepb.DatabaseSchemaMetadata) {
	for _, schema := range metadata.Schemas {
		for _, table := range schema.Tables {
			for _, column := range table.Columns {
				column.Position = 0
			}
		}
	}
}

func sortViewsByName(views []*storepb.ViewMetadata) {
	slices.SortFunc(views, func(a, b *storepb.ViewMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}

func sortMaterializedViewsByName(mvs []*storepb.MaterializedViewMetadata) {
	slices.SortFunc(mvs, func(a, b *storepb.MaterializedViewMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}

func sortFunctionsByName(functions []*storepb.FunctionMetadata) {
	slices.SortFunc(functions, func(a, b *storepb.FunctionMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}

func sortSequencesByName(sequences []*storepb.SequenceMetadata) {
	slices.SortFunc(sequences, func(a, b *storepb.SequenceMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}

func sortExtensionsByName(extensions []*storepb.ExtensionMetadata) {
	slices.SortFunc(extensions, func(a, b *storepb.ExtensionMetadata) int {
		return strings.Compare(a.Name, b.Name)
	})
}
